{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create missing mask for train, val, test tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Licensed under the Apache License, Version 2.\n",
    "* By Siyi Du, 2024\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join, dirname\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create_missing_mask(data_tabular_path, mask_path, random_seed, missing_strategy, missing_rate)\n",
    ": 값 단위 또는 특징 단위로 무작위로 결측값을 생성하는 마스크 생성\n",
    "'''\n",
    "def create_missing_mask(data_tabular_path, mask_path, random_seed, missing_strategy, missing_rate):\n",
    "    '''\n",
    "    missing_strategy: value (random value missingness) or feature (random feature missingness)\n",
    "                      value: 개별 값 단위로 랜덤하게 결측값 생성\n",
    "                      feature: 특정 열 전체를 랜덤하게 결측값 생성\n",
    "    missing_rate: 0.0-1.0\n",
    "    '''\n",
    "    data_tabular = np.array(pd.read_csv(data_tabular_path, header=None))\n",
    "    print(f'data tabular shape: {data_tabular.shape}')\n",
    "    np.random.seed(random_seed)\n",
    "    M, N = data_tabular.shape[0], data_tabular.shape[1]\n",
    "    \n",
    "    if missing_strategy == 'value':\n",
    "        missing_mask_data = np.zeros((M*N), dtype=bool)\n",
    "        mask_pos = np.random.choice(M*N, size=int(M*N*missing_rate), replace=False)\n",
    "        missing_mask_data[mask_pos] = True\n",
    "        missing_mask_data = missing_mask_data.reshape((M,N))\n",
    "        \n",
    "    elif missing_strategy == 'feature':\n",
    "        missing_mask_data = np.zeros((M,N), dtype=bool)\n",
    "        mask_pos = np.random.choice(N, size=int(N*missing_rate), replace=False)\n",
    "        missing_mask_data[:,mask_pos] = True\n",
    "        \n",
    "    else:\n",
    "        raise print('Only support value and feature missing strategy')\n",
    "    \n",
    "    np.save(mask_path, missing_mask_data)\n",
    "    print(f'Real missing rate: {missing_mask_data.sum()/missing_mask_data.size}')\n",
    "    print(f'Save missing mask to {mask_path}')\n",
    "    return missing_mask_data\n",
    "\n",
    "'''\n",
    "create_certain_missing_mask(data_tabular_path, mask_path, mask_pos_order, missing_strategy, missing_rate)\n",
    ": 특정 순서를 기반하여 결측값 생성 마스크.\n",
    "'''\n",
    "def create_certain_missing_mask(data_tabular_path, mask_path, mask_pos_order, missing_strategy, missing_rate):\n",
    "    '''\n",
    "    Create mask according to a mask order list (for MI and LI feature missingness)\n",
    "        MI: 랜덤 포레스트의 특징 중요도 내림차순 (중요도가 높은 특징 순서)\n",
    "        LI: 랜덤 포레스트의 특징 중요도 올림차순 (중요도가 낮은 특징 순서)\n",
    "    '''\n",
    "    data_tabular = np.array(pd.read_csv(data_tabular_path, header=None))\n",
    "    print(f'data tabular shape: {data_tabular.shape}')\n",
    "    M, N = data_tabular.shape[0], data_tabular.shape[1]\n",
    "    assert N == len(mask_pos_order)\n",
    "    mask_pos = mask_pos_order[:int(N*missing_rate)]\n",
    "    missing_mask_data = np.zeros((M,N), dtype=bool)\n",
    "    missing_mask_data[:,mask_pos] = True\n",
    "    np.save(mask_path, missing_mask_data)\n",
    "    print(f'Real missing rate: {missing_mask_data.sum()/missing_mask_data.size}')\n",
    "    print(f'Save missing mask to {mask_path}')\n",
    "    return missing_mask_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change to your own path\n",
    "FEATURES = '/data/ephemeral/home/data/base_features'\n",
    "MASK_PATH = join(FEATURES, 'missing_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data tabular shape: (106676, 16)\n",
      "Real missing rate: 0.29999953129101203\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_train_noOH_all_views_reordered_dvm_value_0.3.npy\n",
      "data tabular shape: (26669, 16)\n",
      "Real missing rate: 0.29999953129101203\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_val_noOH_all_views_reordered_dvm_value_0.3.npy\n",
      "data tabular shape: (33337, 16)\n",
      "Real missing rate: 0.2999988751237364\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_test_noOH_all_views_reordered_dvm_value_0.3.npy\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 개별 값 단위로 무작위 결측값 생성\n",
    "missing_strategy = 'value'\n",
    "# 결측값 비율\n",
    "missing_rate = 0.3\n",
    "target = 'dvm'\n",
    "\n",
    "train_name = 'dvm_features_train_noOH_all_views_reordered.csv'\n",
    "val_name = 'dvm_features_val_noOH_all_views_reordered.csv'\n",
    "test_name = 'dvm_features_test_noOH_all_views_reordered.csv'\n",
    "for name, seed, split in zip([train_name, val_name, test_name], [2021,2022,2023], ['train', 'val', 'test']):\n",
    "    save_mask_path = join(MASK_PATH, f'{name[:-4]}_{target}_{missing_strategy}_{missing_rate}.npy')\n",
    "    path = join(FEATURES, name)\n",
    "    # print(path)\n",
    "    create_missing_mask(path, save_mask_path, seed, missing_strategy, missing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data tabular shape: (106676, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_train_noOH_all_views_reordered_dvm_feature_0.3.npy\n",
      "data tabular shape: (26669, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_val_noOH_all_views_reordered_dvm_feature_0.3.npy\n",
      "data tabular shape: (33337, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_test_noOH_all_views_reordered_dvm_feature_0.3.npy\n"
     ]
    }
   ],
   "source": [
    "# 특정 열 전체를 랜덤하게 결측값 생성\n",
    "missing_strategy = 'feature'\n",
    "\n",
    "train_name = 'dvm_features_train_noOH_all_views_reordered.csv'\n",
    "val_name = 'dvm_features_val_noOH_all_views_reordered.csv'\n",
    "test_name = 'dvm_features_test_noOH_all_views_reordered.csv'\n",
    "for name, seed, split in zip([train_name, val_name, test_name], [2022,2022,2022], ['train', 'val', 'test']):\n",
    "    save_mask_path = join(MASK_PATH, f'{name[:-4]}_{target}_{missing_strategy}_{missing_rate}.npy')\n",
    "    path = join(FEATURES, name)\n",
    "    # print(path)\n",
    "    create_missing_mask(path, save_mask_path, seed, missing_strategy, missing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True False  True False False False  True False\n",
      " False False False False]\n",
      "[False False False  True  True False  True False False False  True False\n",
      " False False False False]\n",
      "[False False False  True  True False  True False False False  True False\n",
      " False False False False]\n"
     ]
    }
   ],
   "source": [
    "# Check train, val, test to miss the same columns\n",
    "# 결측값 마스크 일관성 확인\n",
    "\n",
    "train_np = np.load(join(MASK_PATH, f'{train_name[:-4]}_dvm_feature_0.3.npy'))\n",
    "val_np = np.load(join(MASK_PATH, f'{val_name[:-4]}_dvm_feature_0.3.npy'))\n",
    "test_np = np.load(join(MASK_PATH, f'{test_name[:-4]}_dvm_feature_0.3.npy'))\n",
    "print(train_np[0])\n",
    "print(val_np[0])\n",
    "print(test_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask based on importance\n",
    "\n",
    "Random Forest 분류기를 사용해서 훈련 데이터로 학습하고 테스트 테이터 예측 수행하여 계산\n",
    "\n",
    "-> Masked 값을 찾는 것이 아닌, 레이블 값 학습과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RandomForest 결과 ===\n",
      "MSE: 0.0004\n",
      "R² Score: 0.9996\n",
      "\n",
      "=== GradientBoosting 결과 ===\n",
      "MSE: 0.1190\n",
      "R² Score: 0.8821\n",
      "\n",
      "=== XGBoost 결과 ===\n",
      "MSE: 0.0028\n",
      "R² Score: 0.9973\n",
      "\n",
      "=== 모델 성능 비교 ===\n",
      "              Model       MSE  R² Score\n",
      "0      RandomForest  0.000370  0.999634\n",
      "1  GradientBoosting  0.119050  0.882085\n",
      "2           XGBoost  0.002773  0.997253\n",
      "\n",
      "데이터 컬럼 수: 16\n",
      "정의된 컬럼명 수: 16\n",
      "\n",
      "=== RandomForest 특징 중요도 ===\n",
      "               feature  importance\n",
      "1             Genmodel    0.313634\n",
      "12         Entry_price    0.171641\n",
      "14  First_release_year    0.136155\n",
      "13                Year    0.099356\n",
      "6            Wheelbase    0.091945\n",
      "8                Width    0.060145\n",
      "0                Maker    0.057269\n",
      "9               Length    0.028472\n",
      "7               Height    0.024672\n",
      "3             Bodytype    0.008187\n",
      "15         Engine_size    0.005964\n",
      "10            Seat_num    0.001499\n",
      "11            Door_num    0.001006\n",
      "5            Fuel_type    0.000042\n",
      "4              Gearbox    0.000008\n",
      "2                Color    0.000007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 컬럼명 정의\n",
    "reordered_column_name = ['Maker', 'Genmodel', 'Color', 'Bodytype', 'Gearbox', 'Fuel_type',\n",
    "                'Wheelbase', 'Height', 'Width', 'Length', 'Seat_num', 'Door_num', 'Entry_price', \n",
    "                'Year', 'First_release_year', 'Engine_size']\n",
    "\n",
    "# 데이터 로드\n",
    "X_train = pd.read_csv(join(FEATURES, 'dvm_features_train_noOH_all_views_reordered.csv'), header=None)\n",
    "X_test = pd.read_csv(join(FEATURES, f'dvm_features_test_noOH_all_views_reordered.csv'), header=None)\n",
    "y_train = torch.load(join(FEATURES, 'labels_model_all_train_all_views.pt'))\n",
    "y_test = torch.load(join(FEATURES, 'labels_model_all_test_all_views.pt'))\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 1. RandomForest\n",
    "print(\"=== RandomForest 결과 ===\")\n",
    "rf = RandomForestRegressor(random_state=2022)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, rf_pred)\n",
    "rf_r2 = r2_score(y_test, rf_pred)\n",
    "print(f\"MSE: {rf_mse:.4f}\")\n",
    "print(f\"R² Score: {rf_r2:.4f}\")\n",
    "\n",
    "# 2. GradientBoosting\n",
    "print(\"\\n=== GradientBoosting 결과 ===\")\n",
    "gb = GradientBoostingRegressor(random_state=2022)\n",
    "gb.fit(X_train_scaled, y_train)\n",
    "gb_pred = gb.predict(X_test_scaled)\n",
    "\n",
    "gb_mse = mean_squared_error(y_test, gb_pred)\n",
    "gb_r2 = r2_score(y_test, gb_pred)\n",
    "print(f\"MSE: {gb_mse:.4f}\")\n",
    "print(f\"R² Score: {gb_r2:.4f}\")\n",
    "\n",
    "# 3. XGBoost\n",
    "print(\"\\n=== XGBoost 결과 ===\")\n",
    "xgb = XGBRegressor(random_state=2022)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "xgb_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "xgb_mse = mean_squared_error(y_test, xgb_pred)\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)\n",
    "print(f\"MSE: {xgb_mse:.4f}\")\n",
    "print(f\"R² Score: {xgb_r2:.4f}\")\n",
    "\n",
    "# 모델 비교\n",
    "print(\"\\n=== 모델 성능 비교 ===\")\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['RandomForest', 'GradientBoosting', 'XGBoost'],\n",
    "    'MSE': [rf_mse, gb_mse, xgb_mse],\n",
    "    'R² Score': [rf_r2, gb_r2, xgb_r2]\n",
    "})\n",
    "print(results)\n",
    "\n",
    "# 컬럼 수 확인\n",
    "print(f\"\\n데이터 컬럼 수: {X_train.shape[1]}\")\n",
    "print(f\"정의된 컬럼명 수: {len(reordered_column_name)}\")\n",
    "\n",
    "# 가장 좋은 모델의 특징 중요도 확인\n",
    "best_model = min([(rf_mse, rf, 'RandomForest'), \n",
    "                 (gb_mse, gb, 'GradientBoosting'), \n",
    "                 (xgb_mse, xgb, 'XGBoost')], \n",
    "                key=lambda x: x[0])\n",
    "\n",
    "print(f\"\\n=== {best_model[2]} 특징 중요도 ===\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': reordered_column_name,\n",
    "    'importance': best_model[1].feature_importances_\n",
    "})\n",
    "print(feature_importance.sort_values('importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genmodel', 'Entry_price', 'First_release_year', 'Year', 'Wheelbase', 'Width', 'Maker', 'Length', 'Height', 'Bodytype', 'Engine_size', 'Seat_num', 'Door_num', 'Fuel_type', 'Gearbox', 'Color']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Random Forest의 특징 중요도 분석\n",
    ": 각 특징이 모델 성능에 얼마나 기여했는지를 평가\n",
    "\n",
    "-> 라벨에 대해 어떤 특징이 중요한지\n",
    "'''\n",
    "# Get feature importances\n",
    "importances = best_model[1].feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "# MI_indices: 높은 중요도 순서로 정렬\n",
    "MI_indices = np.argsort(importances)[::-1]\n",
    "# LI_indices: 낮은 중요도 순서로 정렬\n",
    "LI_indices = np.argsort(importances)\n",
    "\n",
    "# Get feature names\n",
    "MI_feature_name = [reordered_column_name[x] for x in MI_indices]\n",
    "print(MI_feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data tabular shape: (106676, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_train_noOH_all_views_reordered_dvm_MI_0.3.npy\n",
      "data tabular shape: (26669, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_val_noOH_all_views_reordered_dvm_MI_0.3.npy\n",
      "data tabular shape: (33337, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_test_noOH_all_views_reordered_dvm_MI_0.3.npy\n",
      "data tabular shape: (106676, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_train_noOH_all_views_reordered_dvm_LI_0.3.npy\n",
      "data tabular shape: (26669, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_val_noOH_all_views_reordered_dvm_LI_0.3.npy\n",
      "data tabular shape: (33337, 16)\n",
      "Real missing rate: 0.25\n",
      "Save missing mask to /data/ephemeral/home/data/base_features/missing_mask/dvm_features_test_noOH_all_views_reordered_dvm_LI_0.3.npy\n"
     ]
    }
   ],
   "source": [
    "missing_rate = 0.3\n",
    "\n",
    "missing_strategy = 'MI'\n",
    "train_name = 'dvm_features_train_noOH_all_views_reordered.csv'\n",
    "val_name = 'dvm_features_val_noOH_all_views_reordered.csv'\n",
    "test_name = 'dvm_features_test_noOH_all_views_reordered.csv'\n",
    "for name, split in zip([train_name, val_name, test_name], ['train', 'val', 'test']):\n",
    "    save_mask_path = join(MASK_PATH, f'{name[:-4]}_{target}_{missing_strategy}_{missing_rate}.npy')\n",
    "    path = join(FEATURES, name)\n",
    "    create_certain_missing_mask(path, save_mask_path, MI_indices, missing_strategy, missing_rate)\n",
    "\n",
    "missing_strategy = 'LI'\n",
    "train_name = 'dvm_features_train_noOH_all_views_reordered.csv'\n",
    "val_name = 'dvm_features_val_noOH_all_views_reordered.csv'\n",
    "test_name = 'dvm_features_test_noOH_all_views_reordered.csv'\n",
    "for name, split in zip([train_name, val_name, test_name], ['train', 'val', 'test']):\n",
    "    save_mask_path = join(MASK_PATH, f'{name[:-4]}_{target}_{missing_strategy}_{missing_rate}.npy')\n",
    "    path = join(FEATURES, name)\n",
    "    create_certain_missing_mask(path, save_mask_path, LI_indices, missing_strategy, missing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False False False False False False False\n",
      "  True  True  True False]\n",
      "[False  True False False False False False False False False False False\n",
      "  True  True  True False]\n",
      "[False  True False False False False False False False False False False\n",
      "  True  True  True False]\n"
     ]
    }
   ],
   "source": [
    "train_np = np.load(join(MASK_PATH, f'{train_name[:-4]}_dvm_MI_0.3.npy'))\n",
    "val_np = np.load(join(MASK_PATH, f'{val_name[:-4]}_dvm_MI_0.3.npy'))\n",
    "test_np = np.load(join(MASK_PATH, f'{test_name[:-4]}_dvm_MI_0.3.npy'))\n",
    "print(train_np[0])\n",
    "print(val_np[0])\n",
    "print(test_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
